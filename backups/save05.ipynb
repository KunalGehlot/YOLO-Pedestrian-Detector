{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO v3\n",
    "import os\n",
    "import tqdm\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import struct\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.patches import Rectangle\n",
    "import imageio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                    beta  = self.read_bytes(size) # bias\n",
    "                    gamma = self.read_bytes(size) # scale\n",
    "                    mean  = self.read_bytes(size) # mean\n",
    "                    var   = self.read_bytes(size) # variance            \n",
    "\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
    "\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    \n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='conv_' + str(conv['layer_idx']), \n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\n",
    "    return add([skip_connection, x]) if skip else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the YOLO model\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "        \n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "        \n",
    "    skip_61 = x\n",
    "        \n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "        \n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n"
     ]
    }
   ],
   "source": [
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# make the yolov3 model to predict 80 classes on COCO\n",
    "\n",
    "yolov3 = make_yolov3_model()\n",
    "\n",
    "# load the weights trained on COCO into the model\n",
    "weight_reader = WeightReader('yolov3.weights')\n",
    "weight_reader.load_weights(yolov3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "yolov3.save('yolov3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model\n",
    "yolov3 = load_model('yolov3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3 \n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_netout() that will take each one of the NumPy arrays, one at a time, \n",
    "#and decode the candidate bounding boxes and class predictions\n",
    "def decode_netout(netout, anchors, obj_thresh,  net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        \n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            #objectness = netout[..., :4]\n",
    "            \n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            \n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
    "            \n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            \n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding boxes will be stretched back into the shape of the original image\n",
    "#will allow plotting the original image and draw the bounding boxes, hopefully detecting real objects.\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "#correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "        \n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        \n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "desired_size = 4096\n",
    "\n",
    "im = Image.open('input.jpg')\n",
    "old_size = im.size\n",
    "\n",
    "new_size = tuple([int(x) for x in old_size])\n",
    "\n",
    "im = im.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                    (desired_size-new_size[1])//2))\n",
    "\n",
    "cv2.imwrite('img/Feed.jpg', np.asarray(new_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.listdir('img')\n",
    "img_names = []\n",
    "for img in temp:\n",
    "    img_names.append('img' + '/' + img)\n",
    "\n",
    "temp = img_names[0]\n",
    "index = len(temp) - temp[::-1].find('/')\n",
    "save_path = temp[:index]\n",
    "    \n",
    "splits_w = [[.0, .125], [.125, .25], [.25, .375], [.375, .5], [.5, .625], [.625, .75], [.75, .875], [.875, 1]]\n",
    "splits_h = [[.0, .125], [.125, .25], [.25, .375], [.375, .5], [.5, .625], [.625, .75], [.75, .875], [.875, 1]]\n",
    "\n",
    "for num, image in enumerate(img_names):\n",
    "    im = imageio.imread(image)\n",
    "    h, w = im.shape[:2]\n",
    "        \n",
    "    name = image.split('/')[-1]\n",
    "    for s_h in splits_h:\n",
    "        for s_w in splits_w:\n",
    "            img = im[int(h*s_h[0]):int(h*s_h[1]), int(w*s_w[0]):int(w*s_w[1]), :]\n",
    "            new_w = int(s_w[0]*w)\n",
    "            new_h = int(s_h[0]*h)\n",
    "                \n",
    "            save_name = os.path.join(save_path, f'{num}_{new_h}_{new_w}_split_{name}')\n",
    "            imageio.imwrite(save_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the results above a threshold\n",
    "# takes the list of boxes, known labels, \n",
    "#and our classification threshold as arguments and returns parallel lists of boxes, labels, and scores.\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 1\n",
      "img/0_2560_3584_split_Feed.jpg\n",
      "out/0_2560_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 84.76517796516418\n",
      "person 99.56192970275879\n",
      "person 97.89847135543823\n",
      "Image No -------- 2\n",
      "img/0_2048_3584_split_Feed.jpg\n",
      "out/0_2048_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 3\n",
      "img/0_2048_2560_split_Feed.jpg\n",
      "out/0_2048_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 60.19642949104309\n",
      "person 77.84380316734314\n",
      "person 69.00980472564697\n",
      "person 61.50878667831421\n",
      "person 81.2937319278717\n",
      "person 70.42221426963806\n",
      "person 70.31595706939697\n",
      "person 74.8948335647583\n",
      "person 86.88295483589172\n",
      "person 76.03434324264526\n",
      "person 88.32943439483643\n",
      "person 90.88881015777588\n",
      "person 92.5861120223999\n",
      "Image No -------- 4\n",
      "img/Feed.jpg\n",
      "out/Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 5\n",
      "img/0_3072_1024_split_Feed.jpg\n",
      "out/0_3072_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 6\n",
      "img/0_3072_3072_split_Feed.jpg\n",
      "out/0_3072_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 7\n",
      "img/0_512_512_split_Feed.jpg\n",
      "out/0_512_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 99.3654191493988\n",
      "Image No -------- 8\n",
      "img/0_2048_512_split_Feed.jpg\n",
      "out/0_2048_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 9\n",
      "img/0_2048_2048_split_Feed.jpg\n",
      "out/0_2048_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 10\n",
      "img/0_512_3072_split_Feed.jpg\n",
      "out/0_512_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 11\n",
      "img/0_1024_2560_split_Feed.jpg\n",
      "out/0_1024_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 12\n",
      "img/0_512_1024_split_Feed.jpg\n",
      "out/0_512_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 98.21963906288147\n",
      "Image No -------- 13\n",
      "img/0_1536_1536_split_Feed.jpg\n",
      "out/0_1536_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 14\n",
      "img/0_3584_3072_split_Feed.jpg\n",
      "out/0_3584_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "car 60.71963310241699\n",
      "car 94.90373134613037\n",
      "Image No -------- 15\n",
      "img/0_1536_512_split_Feed.jpg\n",
      "out/0_1536_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 16\n",
      "img/0_1536_2048_split_Feed.jpg\n",
      "out/0_1536_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 17\n",
      "img/0_3072_1536_split_Feed.jpg\n",
      "out/0_3072_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 18\n",
      "img/0_3584_2048_split_Feed.jpg\n",
      "out/0_3584_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 19\n",
      "img/0_1024_3584_split_Feed.jpg\n",
      "out/0_1024_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 20\n",
      "img/0_2560_1024_split_Feed.jpg\n",
      "out/0_2560_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 21\n",
      "img/0_2560_1536_split_Feed.jpg\n",
      "out/0_2560_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 22\n",
      "img/0_0_2048_split_Feed.jpg\n",
      "out/0_0_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 23\n",
      "img/0_1024_3072_split_Feed.jpg\n",
      "out/0_1024_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 65.55660963058472\n",
      "Image No -------- 24\n",
      "img/0_2048_1536_split_Feed.jpg\n",
      "out/0_2048_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 25\n",
      "img/0_1024_512_split_Feed.jpg\n",
      "out/0_1024_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 26\n",
      "img/0_512_3584_split_Feed.jpg\n",
      "out/0_512_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 98.52018356323242\n",
      "person 97.88576364517212\n",
      "person 93.91813278198242\n",
      "person 98.29298257827759\n",
      "Image No -------- 27\n",
      "img/0_1536_3072_split_Feed.jpg\n",
      "out/0_1536_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 28\n",
      "img/0_3584_2560_split_Feed.jpg\n",
      "out/0_3584_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 97.29323387145996\n",
      "person 99.64253306388855\n",
      "Image No -------- 29\n",
      "img/0_1536_2560_split_Feed.jpg\n",
      "out/0_1536_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 30\n",
      "img/0_1536_1024_split_Feed.jpg\n",
      "out/0_1536_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 31\n",
      "img/0_3584_512_split_Feed.jpg\n",
      "out/0_3584_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 32\n",
      "img/0_0_3584_split_Feed.jpg\n",
      "out/0_0_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 33\n",
      "img/0_3072_512_split_Feed.jpg\n",
      "out/0_3072_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 34\n",
      "img/0_3584_1536_split_Feed.jpg\n",
      "out/0_3584_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 35\n",
      "img/0_1536_0_split_Feed.jpg\n",
      "out/0_1536_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 36\n",
      "img/0_2048_3072_split_Feed.jpg\n",
      "out/0_2048_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 37\n",
      "img/0_0_2560_split_Feed.jpg\n",
      "out/0_0_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 98.9149272441864\n",
      "person 98.8499104976654\n",
      "person 99.22505021095276\n",
      "person 98.56864213943481\n",
      "Image No -------- 38\n",
      "img/0_1536_3584_split_Feed.jpg\n",
      "out/0_1536_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 39\n",
      "img/0_2560_0_split_Feed.jpg\n",
      "out/0_2560_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 40\n",
      "img/0_0_3072_split_Feed.jpg\n",
      "out/0_0_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 41\n",
      "img/0_3072_2560_split_Feed.jpg\n",
      "out/0_3072_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 42\n",
      "img/0_2560_3072_split_Feed.jpg\n",
      "out/0_2560_3072_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 43\n",
      "img/0_1024_0_split_Feed.jpg\n",
      "out/0_1024_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 44\n",
      "img/0_0_1024_split_Feed.jpg\n",
      "out/0_0_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 45\n",
      "img/0_0_1536_split_Feed.jpg\n",
      "out/0_0_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 46\n",
      "img/0_512_0_split_Feed.jpg\n",
      "out/0_512_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 93.75441670417786\n",
      "Image No -------- 47\n",
      "img/0_2560_2048_split_Feed.jpg\n",
      "out/0_2560_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 48\n",
      "img/0_512_2048_split_Feed.jpg\n",
      "out/0_512_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 49\n",
      "img/0_1024_2048_split_Feed.jpg\n",
      "out/0_1024_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 50\n",
      "img/0_3072_2048_split_Feed.jpg\n",
      "out/0_3072_2048_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 51\n",
      "img/0_3584_0_split_Feed.jpg\n",
      "out/0_3584_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 52\n",
      "img/0_3072_3584_split_Feed.jpg\n",
      "out/0_3072_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 53\n",
      "img/0_2560_2560_split_Feed.jpg\n",
      "out/0_2560_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 54\n",
      "img/0_3072_0_split_Feed.jpg\n",
      "out/0_3072_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 55\n",
      "img/0_512_1536_split_Feed.jpg\n",
      "out/0_512_1536_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 56\n",
      "img/0_2560_512_split_Feed.jpg\n",
      "out/0_2560_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 57\n",
      "img/0_3584_1024_split_Feed.jpg\n",
      "out/0_3584_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 58\n",
      "img/0_0_0_split_Feed.jpg\n",
      "out/0_0_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 59\n",
      "img/0_0_512_split_Feed.jpg\n",
      "out/0_0_512_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 60\n",
      "img/0_1024_1024_split_Feed.jpg\n",
      "out/0_1024_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 99.59268569946289\n",
      "person 99.88549947738647\n",
      "person 97.24754691123962\n",
      "person 99.53676462173462\n",
      "Image No -------- 61\n",
      "img/0_2048_1024_split_Feed.jpg\n",
      "out/0_2048_1024_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 62\n",
      "img/0_512_2560_split_Feed.jpg\n",
      "out/0_512_2560_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 63\n",
      "img/0_3584_3584_split_Feed.jpg\n",
      "out/0_3584_3584_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "person 99.83065724372864\n",
      "Image No -------- 64\n",
      "img/0_2048_0_split_Feed.jpg\n",
      "out/0_2048_0_split_Feed.jpg\n",
      "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n",
      "Image No -------- 65\n",
      "img/0_1024_1536_split_Feed.jpg\n",
      "out/0_1024_1536_split_Feed.jpg\n"
     ]
    }
   ],
   "source": [
    "temp = os.listdir('img')\n",
    "img_names = []\n",
    "for img in temp:\n",
    "    img_names.append('img' + '/' + img)\n",
    "img_names.remove('img/Feed.jpg')\n",
    "\n",
    "locs = {}\n",
    "input_w, input_h = 416, 416\n",
    "color = (0, 0, 255)\n",
    "\n",
    "for num, im_nm in enumerate(img_names):\n",
    "\n",
    "    im2 = cv2.imread(im_nm)\n",
    "\n",
    "    image, image_w, image_h = load_image_pixels(im_nm, (net_w, net_w))\n",
    "\n",
    "    yolos = yolov3.predict(image)\n",
    "    # summarize the shape of the list of arrays\n",
    "    print([a.shape for a in yolos])\n",
    "\n",
    "    # define the anchors\n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "    # define the probability threshold for detected objects\n",
    "    class_threshold = 0.6\n",
    "    boxes = list()\n",
    "\n",
    "    for i in range(len(yolos)):\n",
    "            # decode the output of the network\n",
    "        boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh,  net_h, net_w)\n",
    "\n",
    "        # correct the sizes of the bounding boxes\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, nms_thresh)\n",
    "\n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        if(v_labels[i] != 'person'):\n",
    "            continue\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        thick = int((width + height) // 900)\n",
    "        cv2.rectangle(im2,(x1, y1), (x2, y2), color, thick)\n",
    "\n",
    "        label = \"(%.3f)\" % (v_scores[i])\n",
    "        cv2.putText(im2, label, (x1, y1 - 12), 0, 0.4, color, thick//3)\n",
    "    outPath = 'out' + '/' + im_nm.split('/')[-1]\n",
    "    cv2.imwrite(outPath, im2)\n",
    "\n",
    "    for i in range(len(v_boxes)):\n",
    "        print(v_labels[i], v_scores[i])\n",
    "\n",
    "    temp2 = []\n",
    "    if(len(v_boxes) > 0):\n",
    "        for i in range(len(v_boxes)):\n",
    "            box = v_boxes[i]\n",
    "            temp2.append([box.ymin, box.xmin, box.ymax, box.xmax])\n",
    "        locs[outPath] = temp2\n",
    "    else:\n",
    "        locs[outPath] = []\n",
    "\n",
    "\n",
    "    print(\"Image No -------- \" + str(num+1))\n",
    "    print(im_nm)\n",
    "    print(outPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.listdir('out')\n",
    "temp.sort()\n",
    "\n",
    "imgMat = []\n",
    "it = 0\n",
    "\n",
    "for i in range(8):\n",
    "    temp2 = []\n",
    "    for j in range(8):\n",
    "        temp2.append(temp[it])\n",
    "        it+=1\n",
    "    imgMat.append(temp2)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = []\n",
    "\n",
    "for i in range(8):\n",
    "    imgLst = []\n",
    "    result = Image.new('RGB', (4096, 512))\n",
    "    for j in range(8):\n",
    "        imgLst.append(Image.open('out/' + imgMat[i][j]))\n",
    "        result.paste(im=imgLst[j], box=(512*(j+1), 0))\n",
    "    pipes.append(result)\n",
    "\n",
    "imageio.imwrite('test.jpg', pipes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResult = Image.new('RGB', (4096, 4096))\n",
    "finalResult.paste(im=pipes[0], box=(0, 0))\n",
    "finalResult.paste(im=pipes[1], box=(0, 512))\n",
    "finalResult.paste(im=pipes[2], box=(0, 1024))\n",
    "finalResult.paste(im=pipes[3], box=(0, 1536))\n",
    "finalResult.paste(im=pipes[4], box=(0, 2048))\n",
    "finalResult.paste(im=pipes[5], box=(0, 2560))\n",
    "finalResult.paste(im=pipes[6], box=(0, 3072))\n",
    "finalResult.paste(im=pipes[7], box=(0, 3584))\n",
    "\n",
    "imageio.imwrite('Final.jpg', finalResult)\n",
    "\n",
    "plt.imshow(pipes[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('tensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2296d55b9db7a781848b521766bd2bc12ee28458bb21d1a06884bc57e1400d5c"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}